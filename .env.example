# FERPlus Realtime Settings
# This file demonstrates all available environment variables.
# Copy this to .env and customize as needed.

# ===== Camera & Frame Processing =====
# Index of the camera device (default: 0)
CAM_INDEX=0

# Video backend (usually left empty for auto-detection)
# Options: CAP_AVFOUNDATION (macOS), CAP_DSHOW (Windows), CAP_MSMF (Windows), etc.
# VIDEO_BACKEND=

# Smoothing window size for temporal emotion averaging (default: 10)
SMOOTH_WINDOW=10

# Confidence threshold for emotion classification (default: 0.45, range: 0.0-1.0)
CONF_THRESH=0.45

# Target frame processing time in milliseconds (0 = no sleep, unlimited FPS)
TARGET_FRAME_MS=0

# ===== Ollama LLM Integration =====
# Enable Ollama integration for emotion-triggered prompts (default: false)
OLLAMA_ENABLED=false

# Ollama server URL (default: http://localhost:11434)
OLLAMA_URL=http://localhost:11434

# Ollama model name (default: llama3.1)
# Can use CrewAI style: ollama/<model_name>
# Example: ollama/deepseek-r1:1.5b
OLLAMA_MODEL=llama3.1

# Inline prompt text (overrides OLLAMA_PROMPT_FILE if set)
# Leave empty to use prompt file instead
OLLAMA_PROMPT=

# Path to prompt file (default: ollama_prompt.txt)
# Lines starting with # are ignored
OLLAMA_PROMPT_FILE=ollama_prompt.txt

# Probability change threshold to trigger Ollama (default: 0.15, range: 0.0-1.0)
# Represents how much emotion probabilities must change to trigger a query
OLLAMA_CHANGE_THRESHOLD=0.15

# Minimum seconds between consecutive Ollama calls (default: 5)
# Prevents spamming the LLM with requests
OLLAMA_MIN_SECONDS_BETWEEN=5

# Minimum confidence required to trigger Ollama (default: uses CONF_THRESH)
# Leave empty or unset to use CONF_THRESH value instead
OLLAMA_MIN_CONF=

# Request timeout in seconds (default: 30)
OLLAMA_TIMEOUT_S=30

# Display Ollama responses as overlay on video (default: true)
# Keeps response visible until the next successful query
OLLAMA_OVERLAY=true

# ===== Examples =====
# Example 1: Using local Ollama with deepseek model
# OLLAMA_ENABLED=true
# OLLAMA_URL=http://localhost:11434
# OLLAMA_MODEL=ollama/deepseek-r1:1.5b
# OLLAMA_CHANGE_THRESHOLD=0.1
# OLLAMA_MIN_SECONDS_BETWEEN=3

# Example 2: Using ngrok tunnel to Ollama server
# OLLAMA_ENABLED=true
# OLLAMA_URL=https://341f48ced197.ngrok-free.app
# OLLAMA_MODEL=ollama/deepseek-r1:1.5b

# Example 3: Custom camera and strict confidence threshold
# CAM_INDEX=1
# CONF_THRESH=0.7
# VIDEO_BACKEND=CAP_DSHOW
